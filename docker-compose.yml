version: "3.8"

services:
  llama2-chat:
    build: .
    container_name: llama2-chat
    ports:
      - "8080:80"
    volumes:
      - .:/app
    environment:
      - PYTHONUNBUFFERED=1
    command: bash start.sh
